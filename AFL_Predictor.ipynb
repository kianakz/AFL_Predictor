{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Packages ==========\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Functions ==========\n",
    "\n",
    "def preprocess(data):\n",
    "    # This function pre-processes the data, and splits the input parameters and the target parameter\n",
    "    # Input: data frame\n",
    "    # Output: data frame, Series\n",
    "    \n",
    "    # Date and the name of the player are irrelevent to the Brownlow votes and slowed down the performance, so I removed them.   \n",
    "    data = pd.DataFrame(data.drop(\"Date\", axis = 1))   \n",
    "    data = pd.DataFrame(data.drop(\"Name\", axis = 1))\n",
    "    data = pd.DataFrame(pd.get_dummies(data))  # Convert categorical variables to indicators\n",
    "    \n",
    "    # Split input and target\n",
    "    x =  pd.DataFrame(data.drop(\"Brownlow Votes\",axis = 1)) # Initialise the input parameters\n",
    "    y = data[\"Brownlow Votes\"] # Initialise the target parameter  \n",
    "    return x, y \n",
    "\n",
    "def get_data_years(data, year_range):\n",
    "    # This function extracts and returns the data that are within the year_range\n",
    "    # Inputs: dataframe, range\n",
    "    # Outputs: data frame\n",
    "    \n",
    "    return data[data['Date'].dt.year.isin(year_range)]   \n",
    "\n",
    "def eval_model(name, target, predicted):\n",
    "    # This function evaluates the accuracy of a model prediction using 3 metrics: accuracy, f_score and mean absolute error, and prints the results\n",
    "    # Inputs: String, Numpy array, Numpy array\n",
    "    # Output: float, float, float\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(target, predicted)\n",
    "    f_score = metrics.f1_score(target, predicted, average = 'weighted')  # Since our data is imbalanced (we have more 0 Brownlow votes than the other ones, f_score can be a better metric)\n",
    "    abs_error = metrics.mean_absolute_error(target, predicted) # To compute the absolute error of the model. This helps us to get a sense of closeness of predictions to the target\n",
    "    print_res(name, accuracy, f_score, abs_error) # print the results\n",
    "    return accuracy, f_score, abs_error \n",
    "    \n",
    "    \n",
    "def print_res(name, accuracy, f_score, abs_error):\n",
    "    # This function prints the results of evaluation\n",
    "    # Inputs: String, float, float, float\n",
    "    # Output: None\n",
    "    \n",
    "    print(name+ \":\\n\")\n",
    "    print(\"This model is {:.2f}% accurate\".format(accuracy*100.0))\n",
    "    print(\"The f_score is {:.2f}%\".format(f_score*100.0))\n",
    "    print(\"The absolute error is {:.2f}%\\n\".format(abs_error))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Pre-processing ==========\n",
    "\n",
    "raw_data = pd.read_csv(\"RawData.csv\")\n",
    "raw_data['Date'] = pd.to_datetime(raw_data['Date']) # Modify the 'Date' column to 'datetime' format to be able to select years\n",
    "\n",
    "# Split the sets. I used 2003 to 2005 for cross validation. 2006 and 2015 for training set \n",
    "training_set = get_data_years(raw_data, range(2006, 2016))\n",
    "cross_val_set = get_data_years(raw_data, range(2003, 2006))\n",
    "test_set =  get_data_years(raw_data, range(2016, 2020))\n",
    "\n",
    "# Preprocess the data\n",
    "x_train, y_train = preprocess(training_set)\n",
    "x_cross_val, y_cross_val = preprocess(cross_val_set)\n",
    "x_test, y_test = preprocess(test_set)\n",
    "\n",
    "\n",
    "# I ran into an issue that certain teams only appeared in one set and not the others. To keep the number of features the same \n",
    "# for all the data sets I removed the features corresponding to those teams\n",
    "\n",
    "for col in x_train.columns:\n",
    "    if col not in x_cross_val.columns:\n",
    "         x_train.drop(col, inplace=True, axis=1)\n",
    "            \n",
    "for col in x_test.columns:\n",
    "    if col not in x_cross_val.columns:\n",
    "         x_test.drop(col, inplace=True, axis=1)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========== Modelling ==========\n",
    "# I experimented with 3 different models and tested their efficienies\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(solver='sag', max_iter = 5000)\n",
    "log_reg.fit(x_train, y_train) # fit the parameters into the model\n",
    "\n",
    "# Neural networks: MLP classifier\n",
    "mlp = MLPClassifier(random_state=1, max_iter=5000)\n",
    "mlp.fit(x_train, y_train)\n",
    "\n",
    "# Decision tree: Random Forest classifer\n",
    "r_forest = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "r_forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression:\n",
      "\n",
      "This model is 93.81% accurate\n",
      "The f_score is 91.36%\n",
      "The absolute error is 0.12%\n",
      "\n",
      "MLP:\n",
      "\n",
      "This model is 93.21% accurate\n",
      "The f_score is 91.36%\n",
      "The absolute error is 0.12%\n",
      "\n",
      "Random forest:\n",
      "\n",
      "This model is 93.51% accurate\n",
      "The f_score is 90.38%\n",
      "The absolute error is 0.13%\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.935132478807486, 0.9037859293845576, 0.12973504238502806)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========== Test ==========\n",
    "\n",
    "# Predict\n",
    "y_pred_reg = log_reg.predict(x_cross_val) \n",
    "y_pred_mlp = mlp.predict(x_cross_val) \n",
    "y_pred_forest = r_forest.predict(x_cross_val)\n",
    "\n",
    "# Evaluate \n",
    "eval_model(\"Logistic regression\", y_cross_val, y_pred_reg) # evaluate the regression model\n",
    "eval_model(\"MLP\", y_cross_val, y_pred_mlp) # evaluate the MLP model\n",
    "eval_model(\"Random forest\", y_cross_val, y_pred_forest) # evaluate the random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model is 94.21% accurate\n",
      "The predicted winners of the 2019 season are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Total Brownlow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Brodie Grundy</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>Patrick Dangerfield</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Dustin Martin</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name  Total Brownlow\n",
       "82         Brodie Grundy            24.0\n",
       "493  Patrick Dangerfield            24.0\n",
       "178        Dustin Martin            21.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========== Example of prediction using logistic regression ==========\n",
    "\n",
    "# Test the accuracy of the model\n",
    "print(\"This model is {:.2f}% accurate\".format(metrics.accuracy_score(y_test, y_pred_test)*100.0))\n",
    "y_pred_test = log_reg.predict(x_test)\n",
    "\n",
    "# Example: predict the winner of Brownlow medal for 2019 season\n",
    "test_set = get_data_years(raw_data, range(2016, 2020))  # re-read the test set to include Name and Date\n",
    "test_set.insert(1,'Predicted Brownlow', y_pred_test) # add the predictions to the data\n",
    "test_2019 = test_set[test_set['Date'].dt.year == 2019] # extract 2019 data \n",
    "res = test_2019.groupby('Name')['Predicted Brownlow'].sum().to_frame(name = 'Total Brownlow').reset_index() # group by player names to calculate the sum of brownlow in the whole season\n",
    "\n",
    "print(\"The predicted winners of the 2019 season are:\")\n",
    "res.nlargest(3, 'Total Brownlow') # Print out the 3 largest total Brownlow votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
